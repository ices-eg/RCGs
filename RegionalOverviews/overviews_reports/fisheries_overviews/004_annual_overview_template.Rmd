---
header-includes: \usepackage{float} \floatplacement{figure}{H} \floatplacement{table}{H}
output:
  word_document:
    fig_caption: yes
    reference_docx: word_template.docx
    toc: yes
    toc_depth: 5
---

```{r guide, include = F}

#Run render_overviews.rmd 

#This script is controlled by the param.csv and the chunks before Title is declared. 

#The style of the docx is controlled by the 

#Title is declared a bit down, so it will fit the filter

#Be aware of all the /n - these controls linebraks and are needed for proper headings

#Maps are created in their own chock to allow for bigger plots. The plot are imported in the general plot chunk

```

```{r 1_setup_param_dir, include = F}

#If running outside knitr, then set wd. When knitting the wd is set to the folder where the .rmd is stored
#setwd("RegionalOverviews")

#Paramters
RDB_download_date <- "23/04/2019"

target_region <- "RCG_NSEA"  #"RCG_NA", "RCG_NSEA", "RCG_BA"
years <- c(2020)

period <- "2020"

figures <- "yes" #yes / no - all figures outputtet to a folder
tables <- "yes" #yes / no - all tables outputtet to a folder

#data_dir <-data_dir <- paste("../../data/002_prepared/", target_region, "/", sep = '') # "Q:/dfad/users/kibi/data/RCG/from_share_point/"
#data_dir <-data_dir <- paste("D:/Grupy robocze/RCG/RCGs Data/2020 data/", target_region, "/", sep = '') # 
data_dir <-data_dir <- paste("C:/use/0_Lucia/6_Working groups/RCG_ISSG/RDB_Data/", target_region, "/", sep = '') # Lucia


#Folder for figures and tables
# table_dir <- paste("../../outputs/", target_region, "/tables/", sep = "")
# figur_dir <- paste("../../outputs/", target_region, "/figures/", sep = "")
# table_dir <- paste("D:/Grupy robocze/RCG/RCGs Outputs/",period,"/", target_region, "/tables/", sep = "")
# figur_dir <- paste("D:/Grupy robocze/RCG/RCGs Outputs/",period,"/", target_region, "/figures/", sep = "")
 table_dir <- paste("C:/use/0_Lucia/6_Working groups/RCG_ISSG/Overviews/CatchEffort/",period,"/", target_region, "/tables/", sep = "")  # Lucia
 figur_dir <- paste("C:/use/0_Lucia/6_Working groups/RCG_ISSG/Overviews/CatchEffort/",period,"/", target_region, "/figures/", sep = "") # Lucia
 

# for SSF
#table_dir <- paste("D:/Grupy robocze/RCG/RCGs Outputs/SSF_", target_region, "/tables/", sep = "")
#figur_dir <- paste("D:/Grupy robocze/RCG/RCGs Outputs/SSF_", target_region, "/figures/", sep = "")


#Landings per stock settings

years_stock <- c(2018, 2019,2020)
period_stock <- "2018-2020"


#Fleet register		
Date_0<-20200101
Date_previous<-20190101
```

```{r 2_setup_lib, include = F}

options(scipen = 999)


library(tidyverse)
library(dplyr)
library(data.table)
library(knitr)
library(stringr)
#library(RCMfunctions) #sharepoint -> RCG Data Group -> R packages
library(rnaturalearth)
library(flextable) # R version 3.6.3
library(TeachingDemos)
```

```{r 3_setup_markdown, include = F}

#Don't set the dpi too high, then the .docx crash

if (figures == "yes") {
  knitr::opts_chunk$set(
  fig.width = 9,
  fig.height = 5,
  fig.path = figur_dir,
  dpi = 300,
  dev = 'png',
  fig.pos = 'H',
  echo = F,
  warning = F,
  message = F,
  error = F,
  comment = F
)
} else {
  knitr::opts_chunk$set(
  fig.width = 9,
  fig.height = 5,
  dpi = 300,
  dev = 'png',
  echo = F,
  warning = F,
  message = F,
  error = F,
  comment = F
)
}

```


```{r 4_source_ref, include = F}

source("../../funs/func_barplot_var_by_one_var_rmd.r")
source("../../funs/func_barplot_var_by_two_var_stacked_rmd.r")
source("../../funs/pointsMap_func.R")
source("../../funs/choroplethMap_func.R")
source("../../funs/scatterpieMap_func.R")
source("../../funs/func_riverplotfun.R")
source("../../funs/FAZ_SEGMENTACAO_COMPRIMENTO_DCF2.R")
source("../../funs/fun_table.R")
source("../../funs/func_determine_what_to_inset.R")

param <-
  read.table(
    paste(
      "graphical_parameters/",
      target_region,
      "/Annual_Overview/AnnualOverview_",
      target_region,
      "_parameters.csv",
      sep = ""
    ),
    sep = ",",
    stringsAsFactors = FALSE,
    header = T
  )

param <- arrange(param, Order)
param$value_of_threshold <- as.numeric(param$value_of_threshold)
param$width <- as.numeric(param$width)
param$height <- as.numeric(param$height)

colour_table <-
  read.table(
    "../../data/aux_colours.txt",
    header = T,
    sep = "\t",
    colClasses = "character",
    na.strings = "",
    comment.char = ""
  )

```

```{r funs, include = F}

filter_df <-
  function(df = df,
           filter_var = filter_var,
           filter = filter) {
    
    if (filter == "" | is.na(filter)) {

      df <- df
    } else {
           filter <- unlist(str_split(filter, ","))
      
      df <- filter(df, !!rlang::sym(filter_var) %in% filter)
      
    }
  }

#Function below from http://michaeljw.com/blog/post/subchunkify/
subchunkify <- function(g, chunk_name = chunk_name, fig_height=7, fig_width=5) {
  g_deparsed <- paste0(deparse(
    function() {g}
  ), collapse = '')
  
  sub_chunk <- paste0("
  `","``{r fig_", chunk_name, ", fig.height=", fig_height, ", fig.width=", fig_width, ", echo=FALSE, result = \"asis\", warning = F, fig.pos = \"H\"}",
  "  \n (", 
    g_deparsed
    , ")()", "  \n ",
  "  \n `","``
  ")
  
  cat(knitr::knit(text = knitr::knit_expand(text = sub_chunk), quiet = TRUE))
  
}

```


```{r title, include = F}

if (target_region == "RCG_NA") {
  front_title <- paste("RDB Catch and Effort Overview North Atlantic, ",  period, "  \n ","![](../../overviews_shiny/www/logo RCG NA NS_EA.png)", sep = "")
} else if (target_region == "RCG_BA") {
  front_title <- paste("RDB Catch and Effort Overview Baltic, ",  period, "  \n ","![](../../overviews_shiny/www/logo RCG BALTIC.PNG)", sep = "")
} else if (target_region == "RCG_NSEA") {
  front_title <- paste("RDB Catch and Effort Overview North Sea and Eastern Arctic, ",  period, "  \n ","![](../../overviews_shiny/www/logo RCG NA NS_EA.png)", sep = "")
}

```

---
title: `r front_title`
date: `r Sys.Date()`
---


```{r data, include = F}

#This needs to be more generic - for easy loading the naming needs to be more generic

if (target_region == "RCG_NA")
{
  load(
    paste(data_dir, "RDB_RCG_NA_CL_2009_2020_prepared_20210428.Rdata", sep = "")
  )
  load(
    paste(data_dir, "RDB_RCG_NA_CE_2009_2020_prepared_20210428.Rdata", sep = "")
  )
}

if (target_region == "RCG_BA")
{
  load(
    paste(data_dir, "RDB_RCG_BA_CL_2009_2020_prepared_20210428.Rdata", sep = "")
  )
  load(
    paste(data_dir, "RDB_RCG_BA_CE_2009_2020_prepared_20210428.Rdata", sep = "")
  )
}
if (target_region == "RCG_NSEA")
{
  load(
    paste(data_dir, "RDB_RCG_NSEA_CL_2009_2020_prepared_20210504.Rdata", sep = "")
  )
  load(
    paste(data_dir, "RDB_RCG_NSEA_CE_2009_2020_prepared_20210504.Rdata", sep = "")
    )
			}	

#Adds IDs [move to preparation]
cl_rcg[, FlagCountry_Loa := paste(FlagCountry, VesselLengthCategory, sep = "_")]
ce_rcg[, FlagCountry_Loa := paste(FlagCountry, VesselLengthCategory, sep = "_")]

# Add to preparation [and convert 2-letter code to 3-letter code]
#colnames(ce_rcg)[colnames(ce_rcg) == "LandingCountry"] <-
#  "LandingCountry2" # <-------------------------------------------------- No more LandingCountry in ce,lines to delete?

# for maps of foreign landings 'LandingCountry' is needed
ce_rcg[,LandingCountry := HarbourCountry]

#Filter
cl_rcg <- as.data.frame(cl_rcg)
cl <- filter(cl_rcg, Year %in% years)
cl <- mutate(cl, Period = period)

ce_rcg <- as.data.frame(ce_rcg)
ce <- filter(ce_rcg, Year %in% years)
ce <- mutate(ce, Period = period)

cl <- droplevels(cl)
ce <- droplevels(ce) 

```

**Disclaimer**

Tables, plots and graphs presented in this document and overviews are made for the coordination purposes of regional fisheries data collection and are not designed for any other use. Data used for the outputs are extracted from the Regional Database (RDB) and EU Fleet Register. Dates of data extractions are stated in Appendix A. Due to different aggregations and reporting authorities, data can differ to those e.g. used for assessments or technical reports.
Member States (MS) are responsible for uploading latest data and the latest year should be viewed as provisional. Data can be resubmitted by a MS for more than one previous year so there might be differences in earlier year reports if countries update back in time. Responsibility for the quality of the data and comparability to other data sources lies with the MS that provided these data.

The respective scripts and calculations used for data displaying are publicly available via the RCG github (https://github.com/ices-eg/RCGs) and subject to change as the work of the group progresses. 

# Introduction

The present Catch and Effort Overview displays summary information on the commercial landings (CL) and commercial effort (CE) statistics included in the Regional Data Base (RDB), which is used to store detailed commercial fisheries and sampling data.

Before the subgroup on Catch, effort and sampling overviews was set up, the different RCGs conducted data analysis and overviews separately with minimal exchange, resulting in redundancies and efficiency loss. Furthermore, a substantial part of the work was being carried out during the RCG meetings themselves and so not readily available to inform RCG preparation and meeting discussions. This group was established to streamline and facilitate the work on the fisheries and sampling data of the MS and prepare data overviews in advance of the RCG meetings.

The RDB is hosted at the International Council for Exploration of the Sea (ICES) and its data is property of EU Member States with usage governed by the RDB data policy (https://www.ices.dk/data/Documents/Data_Policy_RDB.pdf). It’s a regionally coordinated database platform covering fisheries in the North Atlantic Ocean, the North Sea and the Baltic Sea and is a main resource used by the Regional Coordination Groups to coordinate data collection of EU fisheries. This database aims also: 1) To ensure that data can be made available for the coordination of regional fisheries data sampling plans, in particular for the DCF Regional Coordination Groups (RCGs); 2) To provide a regional estimation system such that statistical estimates of quantities of interest can be produced from sample data, in order to deliver data for ICES stock assessments and advice, 3) To serve and facilitate the production of fisheries management advice and status reports, 4) To increase the awareness of fisheries data collected by the users of the RDB and the overall usage of these data. 5) Addresses fishery management needs related to the European Union Common Fisheries

However, it has been recognised for many years that there is a need to have a new version of the RDB which would also store details about how the sampling was performed and enable statistical estimations to be made.

In fact, the current Regional Data Base stores the commercial catch and sample data at detailed level, and here the data format and estimations does not support statistical estimations, even though most of the countries’ sampling are not done in a statistical way the countries never used the RDB for raising/estimating their data. The countries have raised/estimated the data nationally at the institutes and uploaded the data to InterCatch for the stock assessment Expert Groups. That means the stock assessment EG have no information of how the data have been raised/estimated until the data are uploaded into InterCatch, from that point and through the international raising the data and processes are fully documented. InterCatch does neither support statistical estimations. It has therefore been requested to write specifications for a new version of the RDB, which have been given the name ‘Regional DataBase and Estimation System’, RDBES, to make it more obvious that the major part of the RDB is the estimation part.

## Reading the graphs
### Barplots

In (bar)plots, subtitles indicate if all RDB data could be used and are displayed.  Some data can not be displayed in the plots, e.g. due to missing or incorrect values or due to missing referring data (e.g. if no statistical rectangle is given or harbor names are missing, landings in the respective plots can’t be displayed).
The factor x:% in subtitle indicates the percentage of RDB data that are displayed  in the x-variable. y:% in subtitle indicates the percentage of RDB data in the respective y-variable. z:% in subtitle indicate the percentage of complete (i.e., non-missing) RDB rows in variable. 

### Maps

The maps are generated based on complete and available data from the RDB. The subtitles of the header state the subselection that is displayed (e.g. “all Data”, “pelagics”, etc.).  if data cannot be shown on a map (e.g. due to missing information on the area or harbor code), the missing values is given in the figure text below. 

# Overall fleet evolution (All RCGs)
## Number of vessels
Number of vessels by flag country and length class in the EU vessel register (licence indicator == “Y” in 1st January `r years`. Parentesis: variation relative to `r years-1`; red = number decreases; green = number increases; white = number maintains).

```{r table, include=FALSE}
#fleet register
# functions and packages
	require(data.table)

	fleetreg<-data.table()

		# based on full history
	
	dir_data<-paste("../../data\\fleet_reg\\output\\",years,"\\",sep="")
		
	for (ctry in c("BEL","DEU","DNK","ESP","EST","FIN","FRA","GBR","IRL","LTU","LVA","NLD","POL","PRT","SWE"))
		{
		print(ctry)
		fleetreg<-rbind(fleetreg,fread(paste(dir_data,ctry,"_export.csv", sep = ""), sep = ";",stringsAsFactors=FALSE, verbose=FALSE))
		}	

	# subsets data
		fleetreg<-fleetreg[License_Ind=="Y",]

		
	# creates status date date and combines data
	
		fleetreg$year<-0
		fleetreg$previousyear<-0

		fleetreg[Event_Start_Date<=Date_0 & Event_End_Date>=Date_0,year:=Date_0,]
		fleetreg[Event_Start_Date<=Date_previous & Event_End_Date>=Date_previous,previousyear:=Date_previous,]

		fleetreg$Status_date<-0
	
		target_cols<-c("Country_Code","CFR","Event_Code","Event_Start_Date","Event_End_Date","License_Ind","Loa","Ton_Gt","Ton_Oth","Ton_Gts","Power_Main","Power_Aux","Status_date")
	
		dfy<-as.data.frame(fleetreg[year==Date_0,])
		dfy$Status_date<-Date_0
		dfy<-dfy[target_cols]
			
		dfpy<-as.data.frame(fleetreg[previousyear==Date_previous,])
		dfpy$Status_date<-Date_previous
		dfpy<-dfpy[target_cols]

		fleetreg<-as.data.table(rbind(dfy, dfpy))
	
	# a few formats and quality checks
		fleetreg$Power_Main<-as.numeric(fleetreg$Power_Main)
		fleetreg$Ton_Gt<-as.numeric(fleetreg$Ton_Gt)
		# QCA: should yield 0
   	sum(is.na(fleetreg$Power_Main))
		sum(is.na(fleetreg$Ton_Gt))

	# adds Loa classes
		fleetreg<-FAZ_SEGMENTACAO_COMPRIMENTO_DCF2(dados = as.data.frame(fleetreg), coluna = "Loa")
		# QCA: should yield 0
		sum(is.na(fleetreg$SEG_DCF))
		res_fleetreg<-table(fleetreg$SEG_DCF, fleetreg$Country_Code, fleetreg$Status_date)
		res_fleetreg_pwr<-tapply(fleetreg$Power_Main, list(fleetreg$SEG_DCF,fleetreg$Country_Code, fleetreg$Status_date), sum)
		res_fleetreg_gt<-tapply(fleetreg$Ton_Gt, list(fleetreg$SEG_DCF,fleetreg$Country_Code, fleetreg$Status_date), sum)
		res_fleetreg_pwr[is.na(res_fleetreg_pwr)]<-0
		res_fleetreg_gt[is.na(res_fleetreg_gt)]<-0
```



```{r, results = 'asis'}
  pyear<-as.data.frame.matrix(rbind(res_fleetreg[,,1],apply(res_fleetreg[,,1],2,sum)))
  year<-as.data.frame.matrix(rbind(res_fleetreg[,,2],apply(res_fleetreg[,,2],2,sum)))
  year_pyear<-as.data.frame.matrix(rbind((res_fleetreg[,,2]-res_fleetreg[,,1]),apply((res_fleetreg[,,2]-res_fleetreg[,,1]),2,sum)))
ft<-fun_table(year,year_pyear)
ft
```

## Power
Power (1000*kW) by flag country and length class in the EU vessel register (licence indicator == “Y” in 1st January `r years`. Parentesis: variation relative to `r years-1`).

```{r, results = 'asis'}
  pyear<-as.data.frame.matrix(round(rbind(res_fleetreg_pwr[,,1],apply(res_fleetreg_pwr[,,1],2,sum))/1000,1))
  year<-as.data.frame.matrix(round(rbind(res_fleetreg_pwr[,,2],apply(res_fleetreg_pwr[,,2],2,sum))/1000,1))
  year_pyear<-as.data.frame.matrix(round(rbind((res_fleetreg_pwr[,,2]-res_fleetreg_pwr[,,1]),apply((res_fleetreg_pwr[,,2]-res_fleetreg_pwr[,,1]),2,sum))/1000,1))
ft<-fun_table(year,year_pyear)
ft

```

## Gross tonnage
Gross Tonnage(1000*GT) by flag country and length class in the EU vessel register (licence indicator == “Y” in 1st January `r years`. Parentesis: variation relative to `r years-1`).


```{r, results = 'asis'}
  pyear<-as.data.frame.matrix(round(rbind(res_fleetreg_gt[,,1],apply(res_fleetreg_gt[,,1],2,sum))/1000,1))
  year<-as.data.frame.matrix(round(rbind(res_fleetreg_gt[,,2],apply(res_fleetreg_gt[,,2],2,sum))/1000,1))
  year_pyear<-as.data.frame.matrix(round(rbind((res_fleetreg_gt[,,2]-res_fleetreg_gt[,,1]),apply((res_fleetreg_gt[,,2]-res_fleetreg_gt[,,1]),2,sum))/1000,1))
ft<-fun_table(year,year_pyear)
ft
```

```{r map_prep, include = F}

#Setting up all the files needed for the maps ---- copied directly from script 002

# Load shapefiles and Harbour Lists
########################################################################################################################################################################
# Prepare the dataset with coordinates <-----------------------  WORK on this part
# Harbour list

load("../../data/UNLOCODE.rData")

UNLOCODE %>%
  mutate(Harbour = loCode) %>%
  filter(!is.na(Harbour)) %>%
  select(Harbour, lat, lon) -> Harbours

# load shapefile
if (target_region == "RCG_NA")
{
  shp  = sf::st_read("../../data/shapefiles/RCG_NA_FAOareas.shp") %>% filter(F_LEVEL ==
                                                                    'DIVISION') # for NA maps on DIVISIONS level
}

if (target_region == "RCG_BA")
{
  shp  = sf::st_read("../../data/shapefiles/RCG_BA_FAOareas.shp") %>% filter(F_LEVEL ==
                                                                    'SUBDIVISION') # for BA maps on DIVISIONS level -> WATCH OUT ...28.1/...28.2
}
if (target_region == "RCG_NSEA")
{
  shp  = sf::st_read("../../data/shapefiles/RCG_NSEA_FAOareas.shp") %>%  filter(
    F_LEVEL == 'DIVISION' |
      F_LEVEL == 'SUBAREA' |
      F_CODE == '27.3.a.20' | F_CODE == '27.3.a.21'
  )
}

shp %>%
  mutate(AreaMap = F_CODE, Area = F_CODE) -> shp

# For plotting FishingGrounds
cl %>% group_by(FishingGround) %>% distinct(Area) -> FishingGround
shp %>% left_join(FishingGround) %>% group_by(FishingGround) %>% summarise(ID = mean(ID)) -> FAOshpFG
FAOshpFG = cbind(FAOshpFG,  sf::st_coordinates(sf::st_centroid(FAOshpFG$geometry))) %>% mutate(lon = X, lat = Y)

# For plotting Areas
# add centroids - to put areas labels there, and to put piecharts there, creates new columns to the dataset named X, Y
FAOshp = cbind(shp,  sf::st_coordinates(sf::st_centroid(shp$geometry))) %>% mutate(lon = X, lat = Y)

if(target_region=='RCG_BA'){ # fixed wrong calculation of centroid of 27.3.d.30
  FAOshp = FAOshp %>%   
    mutate(X = ifelse(AreaMap=='27.3.d.30', 19.5 ,X), Y =  ifelse(AreaMap=='27.3.d.30',62 ,Y)) %>%
    mutate(lon = X, lat = Y) 
  
  FAOshpFG = FAOshpFG %>% 
    mutate(X = ifelse(FishingGround=='25-32', 20 ,X), Y =  ifelse(FishingGround=='25-32',58 ,Y)) %>% 
    mutate(lon = X, lat = Y) 

}

if (target_region == "RCG_NA")
{
  StatRectshp  = sf::st_read("../../data/shapefiles/RCG_NA_ICESrect.shp")
}

if (target_region == "RCG_BA")
{
  StatRectshp  = sf::st_read("../../data/shapefiles/RCG_BA_ICESrect.shp")# for BA maps on DIVISIONS level -> WATCH OUT ...28.1/...28.2
}
if (target_region == "RCG_NSEA")
{
  StatRectshp  = sf::st_read("../../data/shapefiles/RCG_NSEA_ICESrect.shp")
}

StatRectshp %>% mutate(StatisticalRectangle = ICESNAME) -> StatRectshp
StatRectshp = cbind(StatRectshp,  sf::st_coordinates(sf::st_centroid(StatRectshp$geometry))) %>% mutate(lon = X, lat = Y)

adm_country <- ne_countries(scale = "medium", returnclass = "sf")
adm_unit  = sf::st_read( # needed for GBT because of GBT, ANG, SCT, WLS,...
  '../../data/shapefiles/countries shp/ne_10m_admin_0_map_units.shp'
)
adm_unit %>% filter(ADMIN=='United Kingdom')-> adm_unit
adm_country %>%  mutate(LandingCountry = gu_a3) %>%  select(LandingCountry)-> countries 
adm_unit %>%  mutate(LandingCountry = GU_A3) %>%  select(LandingCountry)-> units
CTRshp = rbind(countries, units)
try(sf::sf_use_s2(FALSE), silent = TRUE) # in the future it may be a good idea to fix CTRshp so it does not causes an error
CTRshp = cbind(CTRshp,  sf::st_coordinates(sf::st_centroid(CTRshp$geometry,of_largest_polygon = TRUE))) %>% mutate(lon = X, lat = Y)
		

# adjust color palette to the ggplot maps
aux_colours_ggplot = c(colour_table$colour5)
names(aux_colours_ggplot) = c(colour_table$Country)
aux_colours_ggplot_rp <- colour_table
aux_colours_ggplot_rp$colour <- aux_colours_ggplot_rp$colour5


```

###### Page break

```{r plots, results = "asis", eval = T}


for (a in unique(param$Section)) {
  param_sec <- filter(param, Section == a)
  cat('  \n')
  cat(paste0("# ", unique(param_sec$Section_name), '  \n'))
  
  for (b in unique(param_sec$Subsection)) {
    param_subsection <- filter(param_sec, Subsection == b)
    
    cat('  \n')
    cat(paste0("## ", unique(param_subsection$Subsection_name), '  \n'))
    
    for (c in unique(param_subsection$Subsubsection)) {
      graph_det <- filter(param_subsection, Subsubsection == c)
      
      cat('  \n')
      cat(paste0("### ", unique(graph_det$Subsubsection_name), '  \n'))
      
      #Select data input
      
      if (unique(graph_det$Data) == "CL") {
        df <- cl
      } else if (unique(graph_det$Data) == "CE") {
        df <- ce
      }
      
      #Filter input
      
      df <-
        filter_df(
          df = df,
          filter_var = unique(graph_det$Filter_var),
          filter = unique(graph_det$Filter)
        )
      
      # bar plots
      for (i in 1:nrow(graph_det))
      {
        
      	pngtxt_name = paste(graph_det$Subsubsection[i], '_',i, '_', graph_det$Graph_type[i], graph_det$Graph_variant[i], sep = '') # added i in case there are two the same graph types in the one subsubsection
  
        if (graph_det$Graph_type[i] == 1)
        {
          res <- barplot_var_by_one_var(
            x = as.data.frame(df),
            Var = graph_det$Var[i] ,
            var1 = graph_det$var1[i],
            tapply_type = graph_det$tapply_type[i],
            type_of_threshold = graph_det$type_of_threshold[i],
            value_of_threshold = graph_det$value_of_threshold[i],
            sorted = graph_det$sorted[i],
            graph_par = eval(parse(text = graph_det$graph_par[i])),
            save_plot_to_list = T,
            filter=graph_det$Filter[i]
          )
          
         subchunkify(res[[2]], pngtxt_name, graph_det$height[i], graph_det$width[i])
          
          if (tables == "yes") {
            write.table(
              res[[1]],
              file =  
                paste(table_dir, pngtxt_name,
                ".txt",
                sep = ""
              ),
              sep = '\t',
              dec = '.',
              row.names = F
            )
          }
    
cat('Figure ',graph_det$Subsubsection[i],'.',i,'. ',' ',res[[3]] ,'\n ',sep='')
        }
        
        cat('  \n ')
        
        if (graph_det$Graph_type[i] == 2)
        {
          res <- barplot_var_by_two_var_stacked(
            x = as.data.frame(df),
            Var = graph_det$Var[i] ,
            var1 = graph_det$var1[i],
            var2 = graph_det$var2[i],
            tapply_type = graph_det$tapply_type[i],
            proportion = graph_det$proportion[i],
            type_of_threshold = graph_det$type_of_threshold[i],
            value_of_threshold = graph_det$value_of_threshold[i],
            sorted = graph_det$sorted[i],
            graph_par = eval(parse(text = graph_det$graph_par[i])),
            legend_par = graph_det$legend_par[i],
            save_plot_to_list = T,
            filter=graph_det$Filter[i]
          )
          
          subchunkify(res[[2]], pngtxt_name, graph_det$height[i], graph_det$width[i])
          
          if (tables == "yes") {
            write.table(
              res[[1]],
              file =
                paste(table_dir, pngtxt_name,
                      ".txt",
                      sep = ""),
              sep = '\t',
              dec = '.',
              row.names = F
            )
          }

          cat('Figure ',graph_det$Subsubsection[i],'.',i ,'. ',res[[3]],'  \n ',sep='')
        }
        
         cat('  \n')

        if (graph_det$Graph_type[i] == 3)
        {
          res <- pointsMap_func(
            df = df,
            var = graph_det$var[i],
            groupBy = graph_det$groupBy[i],
            facet = graph_det$facet[i],
            func = graph_det$func[i],
            type_of_threshold = graph_det$type_of_threshold[i],
            value_of_threshold =  graph_det$value_of_threshold[i],
            points_coord =  eval(parse(text = graph_det$points_coord[i])),
            plot_labels = graph_det$plot_labels[i],
            saveResults = FALSE,
            outputPath = NA,
            Catch_group_name = NA,
            newVarName = graph_det$newVarName[i],
            addExtraShp = graph_det$addExtraShp[i],
            extraShp = eval(parse(text = graph_det$extraShp[i])),
            addToTitle = graph_det$addToTitle[i]
          )

          subchunkify(res[[2]], pngtxt_name, graph_det$height[i], graph_det$width[i])
          
          if (tables == "yes") {
            write.table(
              res[[1]],
              file =
                paste(table_dir, pngtxt_name,
                      ".txt",
                      sep = ""),
              sep = '\t',
              dec = '.',
              row.names = F
            )
          }

          cat('Figure ',graph_det$Subsubsection[i],'.',i,'. ',res[[3]],'  \n ',sep='')
        }

        cat('  \n ')

        if (graph_det$Graph_type[i] == 4)
        {
          res <- choroplethMap_func(
            df = df,
            var = graph_det$var[i],
            groupBy = graph_det$groupBy[i],
            facet = graph_det$facet[i],
            func = graph_det$func[i],
            type_of_threshold = graph_det$type_of_threshold[i],
            value_of_threshold =  graph_det$value_of_threshold[i],
            points_coord =  eval(parse(text = graph_det$points_coord[i])),
            plot_labels = graph_det$plot_labels[i],
            saveResults = FALSE,
            outputPath = NA,
            Catch_group_name = NA,
            newVarName = graph_det$newVarName[i],
            addExtraShp = graph_det$addExtraShp[i],
            extraShp = eval(parse(text = graph_det$extraShp[i])),
            addToTitle = graph_det$addToTitle[i],
            filter_ON = graph_det$filter_ON[i],
            filter_column = graph_det$filter_column[i],
            filter_type = graph_det$filter_type[i],
            filter_func = graph_det$filter_func[i],
            filter_threshold = graph_det$filter_threshold[i],
            filter_facet = graph_det$filter_facet[i]
          )

          subchunkify(res[[2]], pngtxt_name, graph_det$height[i], graph_det$width[i])
          if (tables == "yes") {
            write.table(
              res[[1]],
              file =
                paste(table_dir, pngtxt_name,
                      ".txt",
                      sep = ""),
              sep = '\t',
              dec = '.',
              row.names = F
            )
          }

        cat('Figure ',graph_det$Subsubsection[i],'.',i,'. ',res[[3]],' \n ',sep='')
        }

        cat('  \n ')


        if (graph_det$Graph_type[i] == 5)
        {
          res <- scatterpieMap_func(
            df = df,
            var = graph_det$var[i],
            groupBy = graph_det$groupBy[i],
            groupBy2 = graph_det$groupBy2[i] ,
            facet = graph_det$facet[i],
            func = graph_det$func[i],
            type_of_threshold = graph_det$type_of_threshold[i],
            value_of_threshold =  graph_det$value_of_threshold[i],
            points_coord =  eval(parse(text = graph_det$points_coord[i])),
            plot_labels = graph_det$plot_labels[i],
            saveResults = FALSE,
            outputPath = NA,
            Catch_group_name = NA,
            newVarName = graph_det$newVarName[i],
            addExtraShp = graph_det$addExtraShp[i],
            extraShp = eval(parse(text = graph_det$extraShp[i])),
            color_palette = eval(parse(text = ifelse(graph_det$color_palette[i]=='none',NA, graph_det$color_palette[i]))),
            addToTitle = graph_det$addToTitle[i],
            filter_ON = graph_det$filter_ON[i],
            filter_column = graph_det$filter_column[i],
            filter_type = graph_det$filter_type[i],
            filter_func = graph_det$filter_func[i],
            filter_threshold = graph_det$filter_threshold[i]
          )

          subchunkify(res[[2]], pngtxt_name, graph_det$height[i], graph_det$width[i])
          
          if (tables == "yes") {
            write.table(
              res[[1]],
              file =
                paste(table_dir, pngtxt_name,
                      ".txt",
                      sep = ""),
              sep = '\t',
              dec = '.',
              row.names = F
            )
          }

        cat('Figure ',graph_det$Subsubsection[i],'.',i,'. ',res[[3]],'\n ',sep='')
        }

        cat('  \n ')
        
       if(graph_det$Graph_type[i] == 6){
                res <- riverplotfun(
                 df, 
                 palette=aux_colours_ggplot_rp, 
                 title=paste(graph_det$var1[i]," (left) to ",graph_det$var2[i]," (right) - ",graph_det$newVarName[i]," - ",graph_det$addToTitle[i],sep=""),
                 value=graph_det$Var[i],
                 save=TRUE,
                 addToTitle = graph_det$addToTitle[i],
                 newVarName=graph_det$newVarName[i],
                 var1=graph_det$var1[i],
                 var2=graph_det$var2[i],
                 filename=paste(figur_dir, pngtxt_name,
                          ".png",
                          sep = ""))
                
cat('![plot of chunk ',pngtxt_name,'](',figur_dir,pngtxt_name,'.png)',sep="")
cat('  \n ') 

         cat('Figure ',graph_det$Subsubsection[i],'.',i,'.', res[[2]],'\n ',sep='')
        }
         cat('  \n ') 
      }
    }
  }
}

```

###### Page break

#### Dates of data extraction

The data referring to the present year was collected under the RCG 2021 data call for the 2020 data for the Baltic Sea, North Sea, Eastern Arctic and the North Atlantic regions and downloaded from the system on the 24th of April 2021 with the exception of information detailed in section “2. Overall Fleet Evolution” which was extracted from the EU Fleet Register (https://webgate.ec.europa.eu/fleet-europa/index_en) on the 14th of April 2021.

#### Catch groups

```{r, results = 'asis'}

kable(arrange(summarise(
  group_by(cl, Region, Period, Species, Catch_group),
  tons = round(sum(OfficialLandingCatchWeight_ton), digits = 0)
), Catch_group))

```

#### Mean Landings per stock, `r period_stock`

Landings per year, stock, species, area and vessel flag country can be found in `r paste("\"landings_per_stock_", min(years_stock), "_", max(years_stock), ".csv\"", sep = "")` for `r period_stock`.

Warning: This stock allocation represents variable stock from the RDB and does not represent the currently assessed stock units. The stock variable in the 
RDB is currently being updated.

```{r}

cl_stock <- mutate(filter(cl_rcg, Year %in% years_stock), period = period_stock)
cl_stock <- droplevels(cl_stock)

kable(spread(summarise(
  group_by(cl_stock, Region, Stock, FlagCountry),
  tons = round(sum(OfficialLandingCatchWeight_ton)/length(years_stock), digits = 0)), 
  FlagCountry, tons, fill = "-"))

cl_stock_csv <- summarise(
  group_by(cl_stock, Region, period, Year, Stock, Species, Area, FlagCountry),
  tons = sum(OfficialLandingCatchWeight_ton))

write.csv(cl_stock_csv, paste(table_dir, "landings_per_stock_", min(years_stock), "_", max(years_stock), ".csv", sep = ""), row.names = F)

```


```{r notes}

#TODO ---- 

#Have a look at the barplot function and how to output the figures - espcially for the grouped plots

#Notes ----
#The names of parameter vars could be cleaned up
#Change file names of prep data, so the script is more generic

```


```{r todo, include = F}





```