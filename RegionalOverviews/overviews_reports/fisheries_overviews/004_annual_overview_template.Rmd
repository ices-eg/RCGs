---
header-includes: \usepackage{float} \floatplacement{figure}{H} \floatplacement{table}{H}
output:
  word_document:
    fig_caption: yes
    reference_docx: word_template.docx
    toc: yes
    toc_depth: 5
---

```{r guide, include = F}

#Run render_overviews.rmd 

#This script is controlled by the param.csv and the chunks before Title is declared. 

#The style of the docx is controlled by the 

#Title is declared a bit down, so it will fit the filter

#Be aware of all the /n - these controls linebraks and are needed for proper headings

#Maps are created in their own chock to allow for bigger plots. The plot are imported in the general plot chunk

```

```{r 1_setup_param_dir, include = F}

#If running outside knitr, then set wd. When knitting the wd is set to the folder where the .rmd is stored
#setwd("RegionalOverviews")

#Paramters
RDB_download_date <- "xx/04/2019"

target_region <- "RCG_BA"  #"RCG_NA", "RCG_NSEA", "RCG_BA"
years <- c(2019)

period <- "2019"

figures <- "yes" #yes / no - all figures outputtet to a folder
tables <- "yes" #yes / no - all tabales outputtet to a folder

data_dir <-data_dir <- paste("../../data/002_prepared/", target_region, "/", sep = '') # "Q:/dfad/users/kibi/data/RCG/from_share_point/"

#Folder for figures and tables
table_dir <- paste("../../outputs/", target_region, "/tables/", sep = "")
figur_dir <- paste("../../outputs/", target_region, "/figures/", sep = "")

#Landings per stock settings

years_stock <- c(2017, 2018,2019)
period_stock <- "2017-2019"


#Fleet register		
Date_0<-20190101
Date_previous<-20180101
```

```{r 2_setup_lib, include = F}

options(scipen = 999)

library(tidyverse)
library(dplyr)
library(data.table)
library(knitr)
library(stringr)
library(RCMfunctions) #sharepoint -> RCG Data Group -> R packages
library(rnaturalearth)
library(flextable) # R version 3.6.3
library(TeachingDemos)
```

```{r 3_setup_markdown, include = F}

#Don't set the dpi too high, then the .docx crash

if (figures == "yes") {
  knitr::opts_chunk$set(
  fig.width = 9,
  fig.height = 5,
  fig.path = figur_dir,
  dpi = 300,
  dev = 'png',
  fig.pos = 'H',
  echo = F,
  warning = F,
  message = F,
  error = F,
  comment = F
)
} else {
  knitr::opts_chunk$set(
  fig.width = 9,
  fig.height = 5,
  dpi = 300,
  dev = 'png',
  echo = F,
  warning = F,
  message = F,
  error = F,
  comment = F
)
}

```


```{r 4_source_ref, include = F}

source("../../funs/func_barplot_var_by_one_var_rmd.r")
source("../../funs/func_barplot_var_by_two_var_stacked_rmd.r")
source("../../funs/pointsMap_func.R")
source("../../funs/choroplethMap_func.R")
source("../../funs/scatterpieMap_func.R")
source("../../funs/func_riverplotfun.R")
source("../../funs/FAZ_SEGMENTACAO_COMPRIMENTO_DCF2.R")
source("../../funs/fun_table.R")
source("../../funs/func_determine_what_to_inset.R")

param <-
  read.table(
    paste(
      "graphical_parameters/",
      target_region,
      "/Annual_Overview/AnnualOverview_",
      target_region,
      "_parameters.csv",
      sep = ""
    ),
    sep = ",",
    stringsAsFactors = FALSE,
    header = T
  )

param <- arrange(param, Order)
param$value_of_threshold <- as.numeric(param$value_of_threshold)
param$width <- as.numeric(param$width)
param$height <- as.numeric(param$height)

colour_table <-
  read.table(
    "../../data/aux_colours.txt",
    header = T,
    sep = "\t",
    colClasses = "character",
    na.strings = "",
    comment.char = ""
  )

```

```{r funs, include = F}

filter_df <-
  function(df = df,
           filter_var = filter_var,
           filter = filter) {
    
    if (filter == "" | is.na(filter)) {

      df <- df
    } else {
           filter <- unlist(str_split(filter, ","))
      
      df <- filter(df, !!rlang::sym(filter_var) %in% filter)
      
    }
  }

#Function below from http://michaeljw.com/blog/post/subchunkify/
subchunkify <- function(g, chunk_name = chunk_name, fig_height=7, fig_width=5) {
  g_deparsed <- paste0(deparse(
    function() {g}
  ), collapse = '')
  
  sub_chunk <- paste0("
  `","``{r fig_", chunk_name, ", fig.height=", fig_height, ", fig.width=", fig_width, ", echo=FALSE, result = \"asis\", warning = F, fig.pos = \"H\"}",
  "  \n (", 
    g_deparsed
    , ")()", "  \n ",
  "  \n `","``
  ")
  
  cat(knitr::knit(text = knitr::knit_expand(text = sub_chunk), quiet = TRUE))
  
}

```


```{r title, include = F}

if (target_region == "RCG_NA") {
  front_title <- paste("Annual overview North Atlantic, ",  period, "  \n ","![](../../data/logo.png)", sep = "")
} else if (target_region == "RCG_BA") {
  front_title <- paste("Annual overview Baltic, ",  period, "  \n ","![](../../data/logo.png)", sep = "")
} else if (target_region == "RCG_NSEA") {
  front_title <- paste("Annual overview North Sea and Eastern Arctic, ",  period, "  \n ","![](../../data/logo.png)", sep = "")
}

```

---
title: `r front_title`
date: `r Sys.Date()`
---


```{r data, include = F}

#This needs to be more generic - for easy loading the naming needs to be more generic

if (target_region == "RCG_NA")
{
  load(
    paste(data_dir, "RDB_RCG_NA_CL_2009_2019_prepared_202004191807.Rdata", sep = "")
  )
  load(
    paste(data_dir, "RDB_RCG_NA_CE_2009_2019_prepared_202004191807.Rdata", sep = "")
  )
}

if (target_region == "RCG_BA")
{
  load(
    paste(data_dir, "RDB_RCG_BA_CL_2009_2019_prepared_202004191807.Rdata", sep = "")
  )
  load(
    paste(data_dir, "RDB_RCG_BA_CE_2009_2019_prepared_202004191807.Rdata", sep = "")
  )
}
if (target_region == "RCG_NSEA")
{
  load(
    paste(data_dir, "RDB_RCG_NSEA_CL_2009_2019_prepared_202004191807.Rdata", sep = "")
  )
  load(
    paste(data_dir, "RDB_RCG_NSEA_CE_2009_2019_prepared_202004191807.Rdata", sep = "")
    )
			}	

#Adds IDs [move to preparation]
cl_rcg[, FlagCountry_Loa := paste(FlagCountry, VesselLengthCategory, sep = "_")]
ce_rcg[, FlagCountry_Loa := paste(FlagCountry, VesselLengthCategory, sep = "_")]

# Add to preparation [and convert 2-letter code to 3-letter code]
#colnames(ce_rcg)[colnames(ce_rcg) == "LandingCountry"] <-
#  "LandingCountry2" # <-------------------------------------------------- No more LandingCountry in ce,lines to delete?

# for maps of foreign landings 'LandingCountry' is needed
ce_rcg[,LandingCountry := HarbourCountry]

#Filter

cl <- filter(cl_rcg, Year %in% years)
cl <- mutate(cl, Period = period)
ce <- filter(ce_rcg, Year %in% years)
ce <- mutate(ce, Period = period)

cl <- droplevels(cl)
ce <- droplevels(ce) 

```



# Overall fleet evolution (All RCGs)
## Number of vessels
Number of vessels by flag country and length class in the EU vessel register (licence indicator == “Y” in 1st January `r years`. Parentesis: variation relative to `r years-1`).

```{r table, include=FALSE}
#fleet register
# functions and packages
	require(data.table)

	fleetreg<-data.table()

		# based on full history
	
	dir_data<-paste("../../data\\fleet_reg\\output\\",years,"\\",sep="")
		
	for (ctry in c("BEL","DEU","DNK","ESP","EST","FIN","FRA","GBR","IRL","LTU","LVA","NLD","POL","PRT","SWE"))
		{
		print(ctry)
		fleetreg<-rbind(fleetreg,fread(paste(dir_data,ctry,"_export.csv", sep = ""), sep = ";",stringsAsFactors=FALSE, verbose=FALSE))
		}	

	# subsets data
		fleetreg<-fleetreg[License_Ind=="Y",]

		
	# creates status date date and combines data
	
		fleetreg$year<-0
		fleetreg$previousyear<-0

		fleetreg[Event_Start_Date<=Date_0 & Event_End_Date>=Date_0,year:=Date_0,]
		fleetreg[Event_Start_Date<=Date_previous & Event_End_Date>=Date_previous,previousyear:=Date_previous,]

		fleetreg$Status_date<-0
	
		target_cols<-c("Country_Code","CFR","Event_Code","Event_Start_Date","Event_End_Date","License_Ind","Loa","Ton_Gt","Ton_Oth","Ton_Gts","Power_Main","Power_Aux","Status_date")
	
		dfy<-as.data.frame(fleetreg[year==Date_0,])
		dfy$Status_date<-Date_0
		dfy<-dfy[target_cols]
			
		dfpy<-as.data.frame(fleetreg[previousyear==Date_previous,])
		dfpy$Status_date<-Date_previous
		dfpy<-dfpy[target_cols]

		fleetreg<-as.data.table(rbind(dfy, dfpy))
	
	# a few formats and quality checks
		fleetreg$Power_Main<-as.numeric(fleetreg$Power_Main)
		fleetreg$Ton_Gt<-as.numeric(fleetreg$Ton_Gt)
		# QCA: should yield 0
   	sum(is.na(fleetreg$Power_Main))
		sum(is.na(fleetreg$Ton_Gt))

	# adds Loa classes
		fleetreg<-FAZ_SEGMENTACAO_COMPRIMENTO_DCF2(dados = as.data.frame(fleetreg), coluna = "Loa")
		# QCA: should yield 0
		sum(is.na(fleetreg$SEG_DCF))
		res_fleetreg<-table(fleetreg$SEG_DCF, fleetreg$Country_Code, fleetreg$Status_date)
		res_fleetreg_pwr<-tapply(fleetreg$Power_Main, list(fleetreg$SEG_DCF,fleetreg$Country_Code, fleetreg$Status_date), sum)
		res_fleetreg_gt<-tapply(fleetreg$Ton_Gt, list(fleetreg$SEG_DCF,fleetreg$Country_Code, fleetreg$Status_date), sum)
		res_fleetreg_pwr[is.na(res_fleetreg_pwr)]<-0
		res_fleetreg_gt[is.na(res_fleetreg_gt)]<-0
```



```{r, results = 'asis'}
  pyear<-as.data.frame.matrix(rbind(res_fleetreg[,,1],apply(res_fleetreg[,,1],2,sum)))
  year<-as.data.frame.matrix(rbind(res_fleetreg[,,2],apply(res_fleetreg[,,2],2,sum)))
  year_pyear<-as.data.frame.matrix(rbind((res_fleetreg[,,2]-res_fleetreg[,,1]),apply((res_fleetreg[,,2]-res_fleetreg[,,1]),2,sum)))
ft<-fun_table(year,year_pyear)
ft
```

## Power
Power (1000*kW) by flag country and length class in the EU vessel register (licence indicator == “Y” in 1st January `r years`. Parentesis: variation relative to `r years-1`).

```{r, results = 'asis'}
  pyear<-as.data.frame.matrix(round(rbind(res_fleetreg_pwr[,,1],apply(res_fleetreg_pwr[,,1],2,sum))/1000,1))
  year<-as.data.frame.matrix(round(rbind(res_fleetreg_pwr[,,2],apply(res_fleetreg_pwr[,,2],2,sum))/1000,1))
  year_pyear<-as.data.frame.matrix(round(rbind((res_fleetreg_pwr[,,2]-res_fleetreg_pwr[,,1]),apply((res_fleetreg_pwr[,,2]-res_fleetreg_pwr[,,1]),2,sum))/1000,1))
ft<-fun_table(year,year_pyear)
ft

```

## Gross tonnage
Gross Tonnage(1000*GT) by flag country and length class in the EU vessel register (licence indicator == “Y” in 1st January `r years`. Parentesis: variation relative to `r years-1`).


```{r, results = 'asis'}
  pyear<-as.data.frame.matrix(round(rbind(res_fleetreg_gt[,,1],apply(res_fleetreg_gt[,,1],2,sum))/1000,1))
  year<-as.data.frame.matrix(round(rbind(res_fleetreg_gt[,,2],apply(res_fleetreg_gt[,,2],2,sum))/1000,1))
  year_pyear<-as.data.frame.matrix(round(rbind((res_fleetreg_gt[,,2]-res_fleetreg_gt[,,1]),apply((res_fleetreg_gt[,,2]-res_fleetreg_gt[,,1]),2,sum))/1000,1))
ft<-fun_table(year,year_pyear)
ft
```

```{r map_prep, include = F}

#Setting up all the files needed for the maps ---- copied directly from script 002

# Load shapefiles and Harbour Lists
########################################################################################################################################################################
# Prepare the dataset with coordinates <-----------------------  WORK on this part
# Harbour list

data(UNLOCODE)
UNLOCODE %>%
  mutate(Harbour = loCode) %>%
  filter(!is.na(Harbour)) %>%
  select(Harbour, lat, lon) -> Harbours

# load shapefile
if (target_region == "RCG_NA")
{
  shp  = sf::st_read("../../data/shapefiles/RCG_NA_FAOareas.shp") %>% filter(F_LEVEL ==
                                                                    'DIVISION') # for NA maps on DIVISIONS level
}

if (target_region == "RCG_BA")
{
  shp  = sf::st_read("../../data/shapefiles/RCG_BA_FAOareas.shp") %>% filter(F_LEVEL ==
                                                                    'SUBDIVISION') # for BA maps on DIVISIONS level -> WATCH OUT ...28.1/...28.2
}
if (target_region == "RCG_NSEA")
{
  shp  = sf::st_read("../../data/shapefiles/RCG_NSEA_FAOareas.shp") %>%  filter(
    F_LEVEL == 'DIVISION' |
      F_LEVEL == 'SUBAREA' |
      F_CODE == '27.3.a.20' | F_CODE == '27.3.a.21'
  )
}

shp %>%
  mutate(AreaMap = F_CODE, Area = F_CODE) -> shp

# For plotting FishingGrounds
cl %>% group_by(FishingGround) %>% distinct(Area) -> FishingGround
shp %>% left_join(FishingGround) %>% group_by(FishingGround) %>% summarise(ID = mean(ID)) -> FAOshpFG
FAOshpFG = cbind(FAOshpFG,  sf::st_coordinates(sf::st_centroid(FAOshpFG$geometry))) %>% mutate(lon = X, lat = Y)

# For plotting Areas
# add centroids - to put areas labels there, and to put piecharts there, creates new columns to the dataset named X, Y
FAOshp = cbind(shp,  sf::st_coordinates(sf::st_centroid(shp$geometry))) %>% mutate(lon = X, lat = Y)

if(target_region=='RCG_BA'){ # fixed wrong calculation of centroid of 27.3.d.30
  FAOshp = FAOshp %>%   
    mutate(X = ifelse(AreaMap=='27.3.d.30', 19.5 ,X), Y =  ifelse(AreaMap=='27.3.d.30',62 ,Y)) %>%
    mutate(lon = X, lat = Y) 
  
  FAOshpFG = FAOshpFG %>% 
    mutate(X = ifelse(FishingGround=='25-32', 20 ,X), Y =  ifelse(FishingGround=='25-32',58 ,Y)) %>% 
    mutate(lon = X, lat = Y) 

}

if (target_region == "RCG_NA")
{
  StatRectshp  = sf::st_read("../../data/shapefiles/RCG_NA_ICESrect.shp")
}

if (target_region == "RCG_BA")
{
  StatRectshp  = sf::st_read("../../data/shapefiles/RCG_BA_ICESrect.shp")# for BA maps on DIVISIONS level -> WATCH OUT ...28.1/...28.2
}
if (target_region == "RCG_NSEA")
{
  StatRectshp  = sf::st_read("../../data/shapefiles/RCG_NSEA_ICESrect.shp")
}

StatRectshp %>% mutate(StatisticalRectangle = ICESNAME) -> StatRectshp
StatRectshp = cbind(StatRectshp,  sf::st_coordinates(sf::st_centroid(StatRectshp$geometry))) %>% mutate(lon = X, lat = Y)

adm_country <- ne_countries(scale = "medium", returnclass = "sf")
adm_unit  = sf::st_read( # needed for GBT because of GBT, ANG, SCT, WLS,...
  '../../data/shapefiles/countries shp/ne_10m_admin_0_map_units.shp'
)
adm_unit %>% filter(ADMIN=='United Kingdom')-> adm_unit
adm_country %>%  mutate(LandingCountry = gu_a3) %>%  select(LandingCountry)-> countries 
adm_unit %>%  mutate(LandingCountry = GU_A3) %>%  select(LandingCountry)-> units
CTRshp = rbind(countries, units)
CTRshp = cbind(CTRshp,  sf::st_coordinates(sf::st_centroid(CTRshp$geometry,of_largest_polygon = TRUE))) %>% mutate(lon = X, lat = Y)
		

# adjust color palette to the ggplot maps
aux_colours_ggplot = c(colour_table$colour5)
names(aux_colours_ggplot) = c(colour_table$Country)
aux_colours_ggplot_rp <- colour_table
aux_colours_ggplot_rp$colour <- aux_colours_ggplot_rp$colour5


```

###### Page break

```{r plots, results = "asis", eval = T}


for (a in unique(param$Section)) {
  param_sec <- filter(param, Section == a)
  cat('  \n')
  cat(paste0("# ", unique(param_sec$Section_name), '  \n'))
  
  for (b in unique(param_sec$Subsection)) {
    param_subsection <- filter(param_sec, Subsection == b)
    
    cat('  \n')
    cat(paste0("## ", unique(param_subsection$Subsection_name), '  \n'))
    
    for (c in unique(param_subsection$Subsubsection)) {
      graph_det <- filter(param_subsection, Subsubsection == c)
      
      cat('  \n')
      cat(paste0("### ", unique(graph_det$Subsubsection_name), '  \n'))
      
      #Select data input
      
      if (unique(graph_det$Data == "CL")) {
        df <- cl
      } else if (unique(graph_det$Data == "CE")) {
        df <- ce
      }
      
      #Filter input
      
      df <-
        filter_df(
          df = df,
          filter_var = unique(graph_det$Filter_var),
          filter = unique(graph_det$Filter)
        )
      
      # bar plots
      for (i in 1:nrow(graph_det))
      {
        
      	pngtxt_name = paste(graph_det$Subsubsection[i], '_',i, '_', graph_det$Graph_type[i], graph_det$Graph_variant[i], sep = '') # added i in case there are two the same graph types in the one subsubsection
  
        if (graph_det$Graph_type[i] == 1)
        {
          res <- barplot_var_by_one_var(
            x = as.data.frame(df),
            Var = graph_det$Var[i] ,
            var1 = graph_det$var1[i],
            tapply_type = graph_det$tapply_type[i],
            type_of_threshold = graph_det$type_of_threshold[i],
            value_of_threshold = graph_det$value_of_threshold[i],
            sorted = graph_det$sorted[i],
            graph_par = eval(parse(text = graph_det$graph_par[i])),
            save_plot_to_list = T
          )
          
         subchunkify(res[[2]], pngtxt_name, graph_det$height[i], graph_det$width[i])
          
          if (tables == "yes") {
            write.table(
              res[[1]],
              file =  
                paste(table_dir, pngtxt_name,
                ".txt",
                sep = ""
              ),
              sep = '\t',
              dec = '.',
              row.names = F
            )
          }
    
cat('Figure ',graph_det$Subsubsection[i],'.',i,'. ',' ',res[[3]] ,'\n ',sep='')
        }
        
        cat('  \n ')
        
        if (graph_det$Graph_type[i] == 2)
        {
          res <- barplot_var_by_two_var_stacked(
            x = as.data.frame(df),
            Var = graph_det$Var[i] ,
            var1 = graph_det$var1[i],
            var2 = graph_det$var2[i],
            tapply_type = graph_det$tapply_type[i],
            proportion = graph_det$proportion[i],
            type_of_threshold = graph_det$type_of_threshold[i],
            value_of_threshold = graph_det$value_of_threshold[i],
            sorted = graph_det$sorted[i],
            graph_par = eval(parse(text = graph_det$graph_par[i])),
            legend_par = graph_det$legend_par[i],
            save_plot_to_list = T
          )
          
          subchunkify(res[[2]], pngtxt_name, graph_det$height[i], graph_det$width[i])
          
          if (tables == "yes") {
            write.table(
              res[[1]],
              file =
                paste(table_dir, pngtxt_name,
                      ".txt",
                      sep = ""),
              sep = '\t',
              dec = '.',
              row.names = F
            )
          }

          cat('Figure ',graph_det$Subsubsection[i],'.',i ,'. ',res[[3]],'  \n ',sep='')
        }
        
         cat('  \n')

        if (graph_det$Graph_type[i] == 3)
        {
          res <- pointsMap_func(
            df = df,
            var = graph_det$var[i],
            groupBy = graph_det$groupBy[i],
            facet = graph_det$facet[i],
            func = graph_det$func[i],
            type_of_threshold = graph_det$type_of_threshold[i],
            value_of_threshold =  graph_det$value_of_threshold[i],
            points_coord =  eval(parse(text = graph_det$points_coord[i])),
            plot_labels = graph_det$plot_labels[i],
            saveResults = FALSE,
            outputPath = NA,
            Catch_group_name = NA,
            newVarName = graph_det$newVarName[i],
            addExtraShp = graph_det$addExtraShp[i],
            extraShp = eval(parse(text = graph_det$extraShp[i])),
            addToTitle = graph_det$addToTitle[i]
          )

          subchunkify(res[[2]], pngtxt_name, graph_det$height[i], graph_det$width[i])
          
          if (tables == "yes") {
            write.table(
              res[[1]],
              file =
                paste(table_dir, pngtxt_name,
                      ".txt",
                      sep = ""),
              sep = '\t',
              dec = '.',
              row.names = F
            )
          }

          cat('Figure ',graph_det$Subsubsection[i],'.',i,'. ',res[[3]],'  \n ',sep='')
        }

        cat('  \n ')

        if (graph_det$Graph_type[i] == 4)
        {
          res <- choroplethMap_func(
            df = df,
            var = graph_det$var[i],
            groupBy = graph_det$groupBy[i],
            facet = graph_det$facet[i],
            func = graph_det$func[i],
            type_of_threshold = graph_det$type_of_threshold[i],
            value_of_threshold =  graph_det$value_of_threshold[i],
            points_coord =  eval(parse(text = graph_det$points_coord[i])),
            plot_labels = graph_det$plot_labels[i],
            saveResults = FALSE,
            outputPath = NA,
            Catch_group_name = NA,
            newVarName = graph_det$newVarName[i],
            addExtraShp = graph_det$addExtraShp[i],
            extraShp = eval(parse(text = graph_det$extraShp[i])),
            addToTitle = graph_det$addToTitle[i],
            filter_ON = graph_det$filter_ON[i],
            filter_column = graph_det$filter_column[i],
            filter_type = graph_det$filter_type[i],
            filter_func = graph_det$filter_func[i],
            filter_threshold = graph_det$filter_threshold[i],
            filter_facet = graph_det$filter_facet[i]
          )

          subchunkify(res[[2]], pngtxt_name, graph_det$height[i], graph_det$width[i])
          if (tables == "yes") {
            write.table(
              res[[1]],
              file =
                paste(table_dir, pngtxt_name,
                      ".txt",
                      sep = ""),
              sep = '\t',
              dec = '.',
              row.names = F
            )
          }

        cat('Figure ',graph_det$Subsubsection[i],'.',i,'. ',res[[3]],' \n ',sep='')
        }

        cat('  \n ')


        if (graph_det$Graph_type[i] == 5)
        {
          res <- scatterpieMap_func(
            df = df,
            var = graph_det$var[i],
            groupBy = graph_det$groupBy[i],
            groupBy2 = graph_det$groupBy2[i] ,
            facet = graph_det$facet[i],
            func = graph_det$func[i],
            type_of_threshold = graph_det$type_of_threshold[i],
            value_of_threshold =  graph_det$value_of_threshold[i],
            points_coord =  eval(parse(text = graph_det$points_coord[i])),
            plot_labels = graph_det$plot_labels[i],
            saveResults = FALSE,
            outputPath = NA,
            Catch_group_name = NA,
            newVarName = graph_det$newVarName[i],
            addExtraShp = graph_det$addExtraShp[i],
            extraShp = eval(parse(text = graph_det$extraShp[i])),
            color_palette = eval(parse(text = ifelse(graph_det$color_palette[i]=='none',NA, graph_det$color_palette[i]))),
            addToTitle = graph_det$addToTitle[i],
            filter_ON = graph_det$filter_ON[i],
            filter_column = graph_det$filter_column[i],
            filter_type = graph_det$filter_type[i],
            filter_func = graph_det$filter_func[i],
            filter_threshold = graph_det$filter_threshold[i]
          )

          subchunkify(res[[2]], pngtxt_name, graph_det$height[i], graph_det$width[i])
          
          if (tables == "yes") {
            write.table(
              res[[1]],
              file =
                paste(table_dir, pngtxt_name,
                      ".txt",
                      sep = ""),
              sep = '\t',
              dec = '.',
              row.names = F
            )
          }

        cat('Figure ',graph_det$Subsubsection[i],'.',i,'. ',res[[3]],'\n ',sep='')
        }

        cat('  \n ')
        
       if(graph_det$Graph_type[i] == 6){
                res <- riverplotfun(
                 df, 
                 palette=aux_colours_ggplot_rp, 
                 title=paste(graph_det$var1[i]," (left) to ",graph_det$var2[i]," (right) - ",graph_det$newVarName[i]," - ",graph_det$addToTitle[i],sep=""),
                 value=graph_det$Var[i],
                 save=TRUE,
                 addToTitle = graph_det$addToTitle[i],
                 newVarName=graph_det$newVarName[i],
                 var1=graph_det$var1[i],
                 var2=graph_det$var2[i],
                 filename=paste(figur_dir, pngtxt_name,
                          ".png",
                          sep = ""))
                
cat('![plot of chunk ',pngtxt_name,'](',figur_dir,pngtxt_name,'.png)',sep="")
cat('  \n ') 

         cat('Figure ',graph_det$Subsubsection[i],'.',i,'.', res[[2]],'\n ',sep='')
        }
         cat('  \n ') 
      }
    }
  }
}

```

###### Page break
#### Data
##### Regional database (RDB)

Downloaded `r RDB_download_date`

##### Fleet register

#### Reading the graphs
##### Barplots

##### Maps

#### Catch groups

```{r, results = 'asis'}

kable(arrange(summarise(
  group_by(cl, Region, Period, Species, Catch_group),
  tons = round(sum(OfficialLandingCatchWeight_ton), digits = 0)
), Catch_group))

```

#### Mean Landings per stock, `r period_stock`

Landings per year, stock, species, area and vessel flag country can be found in `r paste("\"landings_per_stock_", min(years_stock), "_", max(years_stock), ".csv\"", sep = "")` for `r period_stock`.

Warning: This stock allocation represents variable stock from the RDB and does not represent the currently assessed stock units. The stock variable in the 
RDB is currently being updated.

```{r}

cl_stock <- mutate(filter(cl_rcg, Year %in% years_stock), period = period_stock)
cl_stock <- droplevels(cl_stock)

kable(spread(summarise(
  group_by(cl_stock, Region, stock, FlagCountry),
  tons = round(sum(OfficialLandingCatchWeight_ton)/length(years_stock), digits = 0)), 
  FlagCountry, tons, fill = "-"))

cl_stock_csv <- summarise(
  group_by(cl_stock, Region, period, Year, stock, Species, Area, FlagCountry),
  tons = sum(OfficialLandingCatchWeight_ton))

write.csv(cl_stock_csv, paste(table_dir, "landings_per_stock_", min(years_stock), "_", max(years_stock), ".csv", sep = ""), row.names = F)

```


```{r notes}

#TODO ---- 

#Have a look at the barplot function and how to output the figures - espcially for the grouped plots

#Notes ----
#The names of parameter vars could be cleaned up
#Change file names of prep data, so the script is more generic

```


```{r todo, include = F}





```